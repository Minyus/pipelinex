## Integration of Kedro with MLflow as Kedro DataSet and Hooks (callbacks)

Kedro DataSet and Hooks (callbacks) are provided to use MLflow without adding any MLflow-related code in the node (task) functions.

- Kedro DataSet
  - `pipelinex.MLflowDataSet`(https://github.com/Minyus/pipelinex/blob/master/src/pipelinex/extras/datasets/mlflow/mlflow_dataset.py)
  
    Kedro Dataset that saves data to or loads data from MLflow. Set `dataset` argument as follows.

    - If `dataset` is set to a Kedro DataSet object or a dictionary, it will be saved/loaded as an MLFlow artifact.
    - If `dataset` is set to a string either {"json", "csv", "xls", "parquet", "png", "jpg", "jpeg", "img", "pkl", "txt", "yml", "yaml"}, Kedro DataSet object will be created with the string as the file extension and will be saved/loaded as an MLflow artifact. Under the hood, the following Kedro DataSet classes will be used (inspired by [Kedro Wings](https://github.com/tamsanh/kedro-wings)).
      ```python
      dataset_dicts = {
        "json": {"type": "json.JSONDataSet"},
        "csv": {"type": "pandas.CSVDataSet"},
        "xls": {"type": "pandas.ExcelDataSet"},
        "parquet": {"type": "pandas.ParquetDataSet"},
        "pkl": {"type": "pickle.PickleDataSet"},
        "png": {"type": "pillow.ImageDataSet"},
        "jpg": {"type": "pillow.ImageDataSet"},
        "jpeg": {"type": "pillow.ImageDataSet"},
        "img": {"type": "pillow.ImageDataSet"},
        "txt": {"type": "text.TextDataSet"},
        "yaml": {"type": "yaml.YAMLDataSet"},
        "yml": {"type": "yaml.YAMLDataSet"},
      }
      ``` 
    - If `dataset` is set to a string "p", the value will be saved/loaded as an MLflow parameter (string).
    - If `dataset` is set to a string "m", the value will be saved/loaded as an MLflow metric (numeric). 
    - If `dataset` is set to None (default), MLflow will not be used.

    Regarding all the options, see the [API document](https://pipelinex.readthedocs.io/en/latest/source/00_api_docs/pipelinex.extras.datasets.mlflow.html#module-pipelinex.extras.datasets.mlflow.mlflow_dataset)

- Kedro Hooks 

  - [`pipelinex.MLflowBasicLoggerHook`](https://github.com/Minyus/pipelinex/blob/master/src/pipelinex/extras/hooks/mlflow/mlflow_basic_logger.py): Configures MLflow logging and logs duration time for the pipeline to MLflow.

  - [`pipelinex.MLflowArtifactsLoggerHook`](https://github.com/Minyus/pipelinex/blob/master/src/pipelinex/extras/hooks/mlflow/mlflow_artifacts_logger.py): Logs artifacts of specified file paths and dataset names to MLflow.
    
  - [`pipelinex.MLflowDataSetsLoggerHook`](https://github.com/Minyus/pipelinex/blob/master/src/pipelinex/extras/hooks/mlflow/mlflow_outputs_logger.py): Logs datasets of (list of) float/int and str classes to MLflow.

  - [`pipelinex.MLflowTimeLoggerHook`](https://github.com/Minyus/pipelinex/blob/master/src/pipelinex/extras/hooks/mlflow/mlflow_time_logger.py): Logs duration time for each node (task) to MLflow and optionally visualizes the execution logs as a Gantt chart by [`plotly.figure_factory.create_gantt`](https://plotly.github.io/plotly.py-docs/generated/plotly.figure_factory.create_gantt.html) if `plotly` is installed. 
  
  - [`pipelinex.AddTransformersHook`](https://github.com/Minyus/pipelinex/blob/master/src/pipelinex/extras/hooks/add_transformers.py): Adds Kedro transformers such as:
    - [`pipelinex.MLflowIOTimeLoggerTransformer`](https://github.com/Minyus/pipelinex/blob/master/src/pipelinex/extras/transformers/mlflow/mlflow_io_time_logger.py): Logs duration time to load and save each dataset with args:
  
  Regarding all the options, see the [API document](https://pipelinex.readthedocs.io/en/latest/source/00_api_docs/pipelinex.extras.hooks.mlflow.html#module-pipelinex.extras.hooks.mlflow)

  MLflow-ready Kedro projects can be generated by the [Kedro starters](https://github.com/Minyus/kedro-starters-sklearn) (Cookiecutter template) which include the following example config:

  ```yaml
  # catalog.yml

  # Write a pickle file & upload to MLflow
  model:
    type: pipelinex.MLflowDataSet
    dataset: pkl

  # Write a csv file & upload to MLflow
  pred_df: 
    type: pipelinex.MLflowDataSet
    dataset: csv

  # Write an MLflow metric
  score:
    type: pipelinex.MLflowDataSet
    dataset: m  
  ```

  ```python
  # catalog.py (alternative to catalog.yml)

  catalog_dict = {
    "model": MLflowDataSet(dataset="pkl"),  # Write a pickle file & upload to MLflow
    "pred_df": MLflowDataSet(dataset="csv"),  # Write a csv file & upload to MLflow
    "score": MLflowDataSet(dataset="m"),  # Write an MLflow metric
  }
  ```

  ```python
  # mlflow_config.py 

  import pipelinex

  mlflow_hooks = (
    pipelinex.MLflowBasicLoggerHook(
        enable_mlflow=True,  # Enable configuring and logging to MLflow
        uri="sqlite:///mlruns/sqlite.db",
        experiment_name="experiment_001",
        artifact_location="./mlruns/experiment_001",
        offset_hours=0,  # Specify the offset hour (e.g. 0 for UTC/GMT +00:00) to log in MLflow
    ),  # Configure and log duration time for the pipeline
    pipelinex.MLflowArtifactsLoggerHook(
        enable_mlflow=True,  # Enable logging to MLflow
        filepaths_before_pipeline_run=[
            "conf/base/parameters.yml"
        ],  # Optionally specify the file paths to log before pipeline is run
        filepaths_after_pipeline_run=[
            "data/06_models/model.pkl"
        ],  # Optionally specify the file paths to log after pipeline is run
    ),  # Log artifacts of specified file paths and dataset names
    pipelinex.MLflowDataSetsLoggerHook(
        enable_mlflow=True,  # Enable logging to MLflow
    ),  # Log output datasets of (list of) float, int, and str classes
    pipelinex.MLflowTimeLoggerHook(
        enable_mlflow=True,  # Enable logging to MLflow
    ),  # Log duration time to run each node (task)
    pipelinex.AddTransformersHook(
        transformers=[
            pipelinex.MLflowIOTimeLoggerTransformer(
                enable_mlflow=True
            )  # Log duration time to load and save each dataset
        ],
    ),  # Add transformers
  )
  ``` 

<p align="center">
<img src="https://raw.githubusercontent.com/Minyus/pipelinex/master/_doc_images/mlflow_ui_metrics.png">
Logged metrics shown in MLflow's UI
</p>

<p align="center">
<img src="https://raw.githubusercontent.com/Minyus/pipelinex/master/_doc_images/mlflow_ui_gantt.png">
Gantt chart for execution time, generated using Plotly, shown in MLflow's UI
</p>


